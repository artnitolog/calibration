\documentclass[12pt]{article}

\usepackage{style}
\usepackage{commands}
\addbibresource{papers.bib}
% \usepackage{subfiles} 

\begin{document}
\begin{titlepage}
\begin{center}

    \includegraphics[width=9cm]{msu.eps}

    \bigskip
    Московский государственный университет имени М. В. Ломоносова

    Факультет вычислительной математики и кибернетики
    
    Кафедра математических методов прогнозирования

    \vspace{1.5cm}

    {\large Васильев Руслан Леонидович}

    \vspace{1.5cm}

    \textbf{\LARGE Калибровка уверенности нейронных сетей}
    
    \vspace{0.5cm}

    {\Large \textit{Calibration of Neural Networks}}

    \vspace{1.5cm}

    {\large КУРСОВАЯ РАБОТА}
    
    \vspace{1.5cm}

    \begin{flushright}
        \parbox{0.4\textwidth}{
            \textbf{Научный руководитель:}\\
            д.ф-м.н., профессор\\
            \emph{А. Г. Дьяконов}
        }
    \end{flushright}

    % \begin{tabular}{p{0.45\textwidth}p{0.45\textwidth}}
    %     Заведующий кафедрой\newline
    %     Математических Методов\newline
    %     Прогнозирования, академик РАН
    %     &
    %     ~\newline~\newline
    %     \hfill\hbox to 0.45\textwidth{\hrulefill~Ю. И. Журавлёв}
    % \\[20mm]
    %     К защите допускаю\newline
    %     \hbox to 0.4\textwidth{<<\hbox to 12mm{\hrulefill}>> \hrulefill~2010 г.}
    %     &
    %     К защите рекомендую\newline
    %     \hbox to 0.45\textwidth{<<\hbox to 12mm{\hrulefill}>> \hrulefill~2010 г.}
    % \end{tabular}

    \vspace{\fill}
    Москва, 2021
\end{center}
\end{titlepage}

\newpage
\tableofcontents

\newpage
% \begin{abstract}
%     Аннотация обычно содержит 
%     краткое описание постановки задачи и~полученных результатов,
%     одним абзацем на 10--15 строк.
%     Цель аннотации "--- обозначить в~общих чертах, о~чём работа,
%     чтобы человек, совершенно не~знакомый с~данной работой,
%     понял, интересна~ли ему эта тема, и~стоит~ли читать дальше.
%     Аннотация собирается в~последнюю очередь
%     путем легкой модификации наиболее важных и~удачных фраз из введения и~заключения.
% \end{abstract}

\section{Введение}

Количество областей, в которых используется глубокое обучение, стремительно растет. Нейронные сети активно применяются для диагностики заболеваний по медицинским изображениям \cite{medical_nn}, используются в алгоритмах управления беспилотными автомобилями \cite{self_driving}, а также для машинного перевода \cite{nmt_google}. 

% Для подобных задач важно не только обучить модель выдавать корректное предсказание, но и получить степень уверенности в нем.
% В подобных задачах важно, чтобы модель выдавала не только корректное предсказание, но и степень уверенности в в своем ответе.
% В подобных задачах, кроме корректного предсказания, важно, чтобы модель выдывала надежные увере
% В подобных задачах важно, чтобы степень уверенности в нем была надежной.
В подобных задачах обычно требуется обучить модель, которая будет выдавать не только корректное предсказание, но и надежную степень уверенности в нем. Под \emph{уверенностью} понимается оценка вероятности прогноза. Например, если алгоритм для большой выборки пациентов предсказывает, что они здоровы с вероятностью 0.9, то мы ожидаем, что $90\%$ из них действительно окажутся здоровыми. Модель, выдающая достоверные вероятности, называется \emph{откалиброванной}. Наряду с интерпретацией предсказаний нейросетей, откалиброванность важна, когда вероятности используются на последующих этапах работы алгоритмов (например, в языковых моделях \cite{nn_lm}).

Современные нейронные сети нередко оказываются плохо откалиброванными \cite{on_cal}. Тем не менее смещенные оценки уверенности выдают и многие другие алгоритмы машинного обучения \cite{good_proba, emp_comparison}. Для <<классических>> моделей были предложены различные техники калибровки, некоторые из которых получили развитие в нейронных сетях.

\section{Постановка задачи}

Пусть решается задача классификации объектов из множества $\mathcal{X}$ с классами ${\mathcal{Y}}=\{1,\dots,K\}$. Предположим, что мы обучили \emph{модель} -- алгоритм, который для каждого $x\in{\mathcal{X}}$ выдает вектор оценок -- \emph{уверенностей} (confidences) $\vec{a}(x)=(a_1(x),\dots,a_K(x))$, $\sum_{j=1}^{K}a_j(x)=1$. Далее объекту приписывается класс, соответствующий наибольшей уверенности: 
\begin{equation*}\hat{y}(x)\coloneqq\underset{j\in \mathcal{Y}}{\argmax{a_j}},\quad \hat{p}(x)\coloneqq a_{\hat{y}}.
\end{equation*}

Оценку $\hat{p}$ мы бы хотели трактовать как вероятность того, что истинная метка $y$ совпадает с предсказанной $\hat{y}$. Если наша оценка достаточно точна, то модель называют \emph{откалиброванной}. Формально определение \emph{откалиброванности} (в \cite{on_cal} -- \engterm{perfect calibration}) можно записать следующим образом:

\begin{equation}\label{eq:perfect_cal_guo}
    \mathbb{P}\left(y=\hat{y}\mid \hat{p}=p\right)=p \quad \forall p\in\left[0, 1\right].
\end{equation}

Существуют и более сильные определения откалиброванности модели, чем \eqref{eq:perfect_cal_guo}. Например, согласно \cite{isotonic} классификатор называется откалиброванным (в оригинале -- \engterm{well-calibrated}), если 
\begin{equation}\label{eq:cw_cal}
    \mathbb{P}(y=j\mid a_j=p) = p \quad \forall j\in\mathcal{Y}, \quad \forall p\in \left[0, 1\right],
\end{equation}
то есть мы ожидаем, что уверенности, выдаваемые для каждого класса (а не только предсказанного), являются откалиброванными. 

В случае реальных данных и моделей мы не можем напрямую проверить \eqref{eq:perfect_cal_guo} и \eqref{eq:cw_cal}, поэтому на помощь приходят различные показатели качества, а также визуализации, которые будут рассмотрены в \autoref{sec:estimate}.

В \autoref{sec:methods} описываются методы, с помощью которых получаются откалиброванные модели. Во-первых, можно \emph{откалибровать} уверенности, то есть найти функцию, отображающую смещенные оценки в откалиброванные. Поиск наилучшего отображения достаточно нетривиален. Во-вторых, можно применить различные техники на этапе обучения, среди которых выделяются специальные модификации функции потерь.

В \autoref{sec:experiments} проводится сравнение реализованных методов калибровки для современных архитектур нейронных сетей, а также показывается, как выбор функции потерь повлиять на откалиброванность.
% Одно из наиболее <<сильных>> определений откалиброванности дается в \cite{dirichlet}:
% \begin{equation}
%     \mathbb{P}(y=j\mid \vec{a}=\vec{p})=p_j \quad \forall j \in \mathcal Y, \quad \forall \vec{p}\in \Delta^{K-1},
% \end{equation}
% где $\Delta^{K-1}=\left\{\vec{p}\in \left[0, 1\right]: \sum_{j=1}^{K}p_j =1\right\}$.


\section{Оценка откалиброванности}\label{sec:estimate}
\subsection{Визуализация}
Покажем, как можно оценить откалиброванность модели в реальных задачах. Для начала упростим задачу до \emph{бинарной классификации}: $\mathcal{Y}=\{0,1\}$ -- пусть наша модель выдает \emph{уверенности} $\hat{p}$ в том, что объект принадлежит положительному классу (под \emph{положительным} понимается $y=1$). Бинарная классификация чаще встречается при использовании <<классических>> алгоритмов машинного обучения: логистическая регрессия, решающий лес, градиентный бустинг над деревьями, наивный байесовский классификатор, метод опорных векторов и другие -- проблемы их калибровки подробно рассматривались в \cite{good_proba, emp_comparison}.

\mpl{rel_intro}{Варианты визуализации надежности алгоритма. Для наглядности были сгенерированы синтетические данные, в качестве модели использован метод опорных векторов (расстояния до разделяющей гиперплоскости отмасштабированы на $[0, 1]$).}

Разобъем множество значений уверенностей $[0, 1]$ на $M$ интервалов $I_m$ равной ширины:
\begin{equation}\label{eq:binning}
I_1= \left[0, \frac{1}{M}\right),\
I_2= \left[\frac{1}{M},\frac{2}{M}\right),\
\dots,\
I_{M-1}= \left[\frac{M-2}{M},\frac{M-1}{M}\right),\
I_{M} = \left[\frac{M-1}{M}, 1\right].
\end{equation}

Обозначим $B_m$ множество индексов тех объектов выборки, значение уверенности для которых лежит в пределах $I_m$. Будем взаимозаменяемо называть $B_m$ и соответствующие им интервалы $I_m$ \emph{бинами} (\engterm{bins}).

В каждом бине $B_m$ посчитаем долю объектов положительного класса $A^1_m$ (\engterm{positive frequency}) и среднюю уверенность $C^1_m$(\engterm{confidence}) в том, что объект принадлежит положительному классу:

\begin{equation}\label{eq:bin_accconf}
    A^1_m=\frac{1}{|B_m|}\sum_{i\in B_m} \mathbb{1}(y_i=1),
    \quad
    C^1_m=\frac{1}{|B_m|}\sum_{i\in B_m} \hat{p}_i.
\end{equation}

Далее построим график $(C^1_m, A^1_m)_{m=1}^M$, который называются \emph{графиком надежности} \cite{reldiag_idea, good_proba} (\engterm{reliability plot/diagram}) -- \autoref{fig:rel_intro} (a). Также полученную кривую иногда называют \emph{калибровочной кривой} (\engterm{calibration curve}). Хорошей откалиброванности соответствует кривая, близкая к диагональной. 

Можно изобразить полученные оценки с помощью гистограммы, которую называют \emph{диаграммой надежности}: на \autoref{fig:rel_intro} (b) красным показывается средняя уверенность, синим -- доля объектов положительного класса, попавших в бин. Если красный столбец выше синего, то алгоритм выдает недостаточно уверенные оценки (\engterm{underconfidence}), если синий выше красного -- слишком большие (\engterm{overconfidence}). Дополнительно на том же графике мы покажем зеленым \emph{вес} бина (\engterm{weight}) -- долю объектов (всех классов), попавших в бин. 

В случае, когда классов $n>2$, диаграммы надежности строятся иначе. Наиболее популярный подход соответствует пониманию откалиброванности в смысле \eqref{eq:perfect_cal_guo}. Для каждого бина $B_m$ оценивается \emph{точность} (\emph{доля правильных ответов}, \engterm{accuracy}) $A_m$ и средняя уверенность в предсказании $C_m$:

\begin{equation}\label{eq:accconf}
    A_m=\frac{1}{|B_m|}\sum_{i\in B_m} \mathbb{1}(y_i=\hat{y}_i),
    \quad
    C_m=\frac{1}{|B_m|}\sum_{i\in B_m} \hat{p}_i.
\end{equation}

\eqref{eq:bin_accconf} и \eqref{eq:accconf} отличаются тем, что в многоклассовом случае $\hat{y}_i$ и $\hat{p}_i$ соответствуют предсказанному классу и уверенности, в то время как в бинарном варианте все считается для положительного класса.
Заметим, что $A_m$ и $C_m$ оценивают соответственно левую и правую части \eqref{eq:perfect_cal_guo}. Их можно изобразить на диаграмме надежности. Для двух классов такой подход проиллюстрирован на \autoref{fig:rel_intro} (c) -- бины с границами $<0.5$ оказываются пустыми, поскольку в бинарной классификации алгоритм относит объект к классу, уверенность в котором $>0.5$.

В \cite{dirichlet} также рассматриваются \emph{поклассовые диаграммы надежности} (\engterm{classwise-reliability diagrams}): для этого мы каждый класс по отдельности объявляем положительным и строим $n$ диаграмм надежности для бинарного случая. И хотя поклассовый подход более полный \eqref{eq:cw_cal}, для большого числа классов (например, 1000 в датасете Imagenet \cite{imagenet}) строить так много графиков будет затруднительно. Поэтому почти всегда используются диаграммы надежности для предсказанных классов \eqref{eq:accconf}.

\subsection{Метрики}
Кроме визуализаций, оценить откалиброванность модели помогают различные \emph{метрики} (под \emph{метрикой} в данной работе понимается показатель качества). Одна из наиболее популярных --- ECE (\engterm{Expected Calibration Error} \cite{bayesian_ece}). Она приближает
$$
\mathbb{E}_{\hat{p}}\left|
\mathbb{P}\left(y=\hat{y}\mid \hat{p}\right)-\hat{p}\right|
$$
с помощью разделения уверенностей по бинам ($l$ -- общее число объектов):
\begin{align}\label{eq:ece}
\ece &=
\sum_{m=1}^{M}
\frac{|B_m|}{n}
\left| A_m - C_m \right| \\
&=
\sum_{m=1}^{M}
\frac{|B_m|}{n}\left|
\frac{1}{|B_m|}\sum_{i\in B_m} \mathbb{1}(y_i=\hat{y}_i)
-
\frac{1}{|B_m|}\sum_{i\in B_m} \hat{p}_i
\right| \nonumber\\
&=
\frac{1}{n}\,\sum_{m=1}^{M}\,
\left|\,
\sum_{i\in B_m} \mathbb{1}(y_i=\hat{y}_i)
-
\sum_{i\in B_m} \hat{p}_i
\,\right|\nonumber.
\end{align}

Сравнивая \eqref{eq:ece} и диаграммы надежности для многоклассовой задачи, замечаем, что $\ece$ в точности равна взвешенному среднему длин отрезков между красными и синими столбцами.

Существуют и другие метрики на основе разбиения уверенностей по бинам, хоть и используются значительно реже. Например, можно посчитать длину максимального разрыва между уверенностью и точностью \cite{bayesian_ece}:
\begin{equation}
    \mce=\max_m \left|A_m - C_m\right|,
\end{equation}
или же учитывать уверенности не только за предсказанный класс, но и за все остальные (\engterm{classwise ECE}) \cite{dirichlet}:

\begin{equation}\label{eq:cwece}
    \cwece=\frac{1}{K}
\sum_{j=1}^K \sum_{m=1}^M
\frac{|B^j_m|}{n}|A^j_m - C^j_m|,
\end{equation}
где $B^j_m, A^j_m, C^j_m$ -- соответственно $m$-й бин, точность и уверенность, если мы выделяем $j$-й класс как положительный, а все остальные собираем в отрицательный (то есть метрика соответствует поклассовым диаграммам надежности).

Вместо равноширинных бинов \eqref{eq:binning} можно использовать равномощные бины --- иногда таким образом строят диаграммы уверенности. В \cite{ace} предлагалось с помощью равномощных бинов считать описанные ранее метрики. Далее везде будет использоваться равноширинная схема. Также, кроме $l_1$-нормы (т.е. усреднения модулей), можно использовать $l_2$ (брать среднеквадратическое) \cite{verified_uncertainty}.

Помимо биннинговых метрик, для оценки откалиброванности модели можно использовать \emph{скоринговые функции ошибки} (\engterm{proper scoring rules}). Мы будем измерять NLL~(\engterm{Negative Log-Likelihood}):
\begin{equation}\label{eq:nll}
    \nll=-\frac{1}{l}\sum_{i=1}^n \log{a_{i, y_i}},
\end{equation}
где $y_i$ -- истинная метка класса $i$-го объекта, $a_{i, y_i}$~-- уверенность алгоритма в ней, $n$~-- общее число объектов, $K$~-- число классов.

Другая скоринговая функция ошибки, с помощью которой можно оценить откалиброванность модели~--- \engterm{Brier Score}:
\begin{equation}
    \bs = \frac{1}{n}\sum_{i=1}^n \sum_{j=1}^K
    \left(a_{ij} - \mathbb{1}(y_i = j)\right)^2.
\end{equation}



\section{Методы калибровки}\label{sec:methods}
% так а мб тут сослаться на бинарную и кучку ссылок со склерн.
% Калибровка является техникой пост-обработки. Если модель заведомо учится предсказывать корректные вероятности (или звезды сошлись так, что она откалибрована -- пример в статье о температурном шкалировании), то данные методы могут быть лишними. Какой использовать? Зависит от задачи и классификатора. А также нужно смотреть на диаграмму.
% <<Функция деформации>>. Параметрические, непараметрические методы.
Методы калибровки можно разделить на две основные группы. Во-первых, можно сделать \emph{постобработку} (\engterm{post-hoc calibration methods}) выходов модели. Для этого используется \emph{функция деформации} (\engterm{calibration map}) — отображение, заменяющее смещенные оценки вероятности на откалиброванные. Ко второй группе относят методы, применяющиеся на этапе обучения модели.

\subsection{Постобработка}
% Можно прокомментировать, почему нельзя использовать обучающую
Поиск функции деформации выполняется на \emph{отложенной выборке} $(x_i,y_i)_{i=1}^{n}$. Обычно используется тот же набор данных, на котором валидируется модель и подбираются гиперпараметры.

\mpl{calibs_binary}{Визуализация различных функций деформации для бинарной классификации (те же данные и модель, что и на \autoref{fig:rel_intro}).}

\subsubsection{Гистограммный биннинг (Histogram binning)}
Изначально метод был предложен в \cite{hist_binning} для калибровки решающих деревьев и наивного байесовского классификатора. Рассмотрим бинарный случай: ищется кусочно-постоянная функция деформации. А именно, множество значений выходных уверенностей разбивается на бины $B_1,\dots,B_M$ (обычно равноширинные \eqref{eq:binning} или равномощные) и оценки, попавшие в $B_m$, заменяются на общую для данного бина $\theta_m$. Чтобы найти $\theta_1,\dots,\theta_M$, решается следующая задача оптимизации:

\begin{equation}\label{eq:hist_binning}
\sum_{m=1}^{M}\sum_{i\in B_m}
\left(\theta_m - y_i\right)^2 \ \to \
\min_{\theta_1,\dots, \theta_M}.
\end{equation}

В такой постановке $\theta_m$ будет равна доле объектов отложенной выборки положительного класса, попавших в бин $B_m$. Функция деформации проиллюстрирована на \autoref{fig:calibs_binary} (a). 

Метод обобщается на многоклассовый случай с помощью стратегии \emph{один-против-всех} (\engterm{one-vs-rest}): каждый класс по отдельности объявляется положительным и строится $K$ кусочно-постоянных функций деформации. На этапе применения выходной вектор вероятностей нормализуется.

% Хотя метод прост в настройке и использовании, выбор числа бинов 

\subsubsection{Изотоническая регрессия (Isotonic regression)}

Метод предложен в \cite{isotonic}. Для бинарного случая по отложенной выборке тоже ищется кусочно-постоянная функция деформации, но число интервалов $M$ и их границы оптимизируются, а на саму функцию дополнительно накладывается требование неубывания. Таким образом, решается следующая задача:

\begin{equation}\label{eq:isotonic}
\sum_{m=1}^{M}\sum_{i\in \tilde{B}_m}
\left(\theta_m - y_i\right)^2 \ \to \
\underset{\substack{
    M \\
    \theta_1 \leqslant \dots \leqslant \theta_M \\
    0=\alpha_0 \leqslant \alpha_1 \leqslant \dots \leqslant \alpha_{M-1} \leqslant \alpha_M = 1
}}{\min,}
\end{equation}
где 
$\tilde{B}_1 =\{i: \alpha_0 \leqslant \hat{p}_i < \alpha_1\},
\dots,
\tilde{B}_{m} =\{i: \alpha_{m-1} \leqslant \hat{p}_i \leqslant \alpha_m\}$. Вид функции проиллюстрирован на \autoref{fig:calibs_binary}.

Изотоническая регрессия обобщается на многоклассовый случай так же, как и гистограммный биннинг.

\subsubsection{Калибровка Платта (Platt Calibration) и ее обобщения}
Изначально метод предложен в \cite{platt} для калибровки метода опорных векторов. Как видно на иллюстрациях \autoref{fig:rel_intro}, \autoref{fig:calibs_binary}, если мы отшкалируем расстояния $r(x)$ от объектов до разделяющей гиперплоскости на $[0, 1]$ и возьмем их в качестве уверенностей в положительном классе, то график надежности будет иметь форму сигмоиды:
% \begin{equation}
%     a'(x) = \sigma \left(\alpha \cdot r(x) + \beta\right), \quad \sigma(z) = \frac{1}{1+e^{-z}}
% \end{equation}
\begin{equation}
    \hat{p}(x) = \frac{1}{1+e^{-(\alpha \cdot r(x) + \beta)}}.
\end{equation}

Коэффициенты масштаба $\alpha$ и сдвига $\beta$ оптимизируются на отложенной выборке с помощью метода максимального правдоподобия. В данном методе функция деформации оказывается непрерывной и допускает различные обобщения на многоклассовую задачу.

Последний линейный слой нейронной сети для объекта $x$ выдает вектор \emph{логитов} (\engterm{logits}): $\vec{z} = (z_1,\dots,z_K)$. Чтобы оценить вероятности классов, вектор логитов пропускают через \engterm{softmax}, $\softmax(\cdot)$:
\begin{equation*}
    \softmax\left(\vec{z}\right)=
    \frac{1}{\sum_{j=1}^{K} {\exp{\left(z_j\right)}}}
    \left(
        {\exp{\left(z_1\right)}},
        \dots,
        {\exp{\left(z_K\right)}}
    \right),
\end{equation*}
тогда обобщить калибровку Платта можно введением параметров масштаба и сдвига для логитов:
% Калибровка Платта обобщается следующим образом \cite{on_cal}: для откалибровнной оценки $a(x)$ находятся параметры масштаба и сдвига для логитов.
\begin{equation}
    a(x) = \softmax(\vec{W}\cdot \vec{z} + \vec{b}).
\end{equation}

Параметры $\vec{W}$ и $\vec{b}$ также оптимизируются с помощью метода максимального правдоподобия на отложенной выборке, что эквивалентно минимизации NLL \eqref{eq:nll}. В зависимости от размерности $\vec{W}$ и $\vec{b}$, можно получить разные обобщения:

\begin{enumerate}
    \item Температурное шкалирование (\engterm{temperature scaling}):
    $$\vec{W}=\frac{1}{T}\in\mathbb{R}, \ T>0, \ \vec{b}=\vec{0}.$$
    
    Обобщение калибровки Платта с единственным скалярным параметром. Метод является одним из наиболее часто используемых. Увеличение температуры $T$ приводит к увеличению неопределенности --- росту энтропии выходного распределения. Уменьшение, напротив, увеличивает уверенность в предсказанном классе. При этом сама классификация остается неизменной.

    \item Векторное шкалировние (\engterm{vector scaling}):
    $$\vec{W}=\operatorname{diag}(\vec{v})\in \mathbb{R}^{K\times K}\text{ --- диагональная матрица}, \vec{v}\in\mathbb{R}^K.$$

    В данном подходе для каждого класса оптимизируется свой коэффициент масштаба (и сдвига, если $\vec{b} \neq \vec{0}$ тоже оптимизируется).

    \item Матричное шкалировние (\engterm{matrix scaling}):
    $$\vec{W}\in \mathbb{R}^{K\times K}, \vec{b}\in\mathbb{R}^K.$$

    Матричное шкалирование является наиболее общей параметризацией в данной группе методов и эквивалентно логистической регрессии в пространстве логитов. Тем не менее при большом числе классов метод имеет слишком много параметров, что может привести к переобучению, а также проблемам со сходимостью.
\end{enumerate}
Заметим, что для реализации любого из перечисленных вариантов достаточно добавить к обученной нейросети линейный слой (нужной размерности).

\subsection{Калибровка на этапе обучения}
Качество работы нейронных сетей сильно зависит от функции потерь, на которую они настраиваются. Чаще всего используется NLL \eqref{eq:nll}. Для одного объекта $x$ она равна кросс-энтропии между истинным вектором классификации $\vec{y}$ и предсказанным распределением $\vec{a}$:
\begin{equation}
    \operatorname{CE}(\vec{y}, \vec{a}) = -\sum_{j=1}^{K} y_j \log{a_j}.
\end{equation}

Чтобы повысить откалиброванность модели, можно модифицировать саму функцию потерь.

\subsubsection{Сглаживание меток (Label smoothing)}

В данном методе вырожденное распределение вектора классификации подменяется более сглаженным. Сила сглаживания регулируется с помощью параметра $\alpha \in [0, 1]$:

\begin{equation}
    \vec{y}=\left(y_1,\dots,y_K\right)
    \mapsto
    \left(
        (1-\alpha)y_1 + \frac{\alpha}{K},
        \dots,
        (1-\alpha)y_K + \frac{\alpha}{K}
    \right)=\vec{y}'.
\end{equation}

С ростом $\alpha$ распределение $\vec{y}'$ становится более равномерным. После данного преобразования минимизируется кросс-энтропия $\operatorname{CE}(\vec{y}',\vec{a})$ между сглаженным вектором классификации и предсказанным распределением.

Хотя использование сглаженных меток при обучении классификатора не новая идея, для калибровки такой подход был предложен в \cite{smoothing}.

\subsubsection{Фокальная ошибка (Focal loss)}

\begin{figure}[!h]
    \includegraphics[width=0.7\textwidth]{focal_loss}
    \centering
    \caption{Фокальная ошибка для одного объекта. $\hat{p}$ --- оценка вероятности для истинного класса}
    \label{fig:focal_loss}
\end{figure}

Изначально фокальная ошибка была использована для устранения проблемы дисбаланса классов \cite{focal_detection}. С точки зрения калибровки уверенности идею впервые использовали в \cite{focal_calib}. Для объекта, принадлежащего $j$-му классу, фокальная ошибка имеет следующий вид:
\begin{equation}
    \operatorname{FL}=-(1-a_{j})^{\gamma}\cdot \log a_j, \quad \gamma \geqslant 0,
\end{equation}
причем функция потерь совпадает с кросс-энтропией при $\gamma=0$. С увеличением $\gamma$, как видим на \autoref{fig:focal_loss}, уменьшается штраф за потери на объектах с уже высокой уверенностью в истинном классе. В то время как кросс-энтропия является верхней оценкой дивергенции Кульбака --- Лейблера между истинным $\vec{y}$ и предсказанным $\vec{a}$ распределением, у фокальной ошибки из оценки вычитается энтропия предсказанного распределения $H(\vec{a})$ \cite{focal_calib}:
\begin{equation*}
    \operatorname{CE}(\vec{y},\vec{a})
    \geqslant
    \operatorname{KL}(\vec{y}||\vec{a}),
    \qquad
    \operatorname{FL}(\vec{y},\vec{a})
    \geqslant
    \operatorname{KL}(\vec{y}||\vec{a})-\gamma\cdot \operatorname{H}(\vec{a}).
\end{equation*}

Получается, оптимизация фокальной ошибки дополнительно увеличивает энтропию предсказанного распределения, то есть помогает в борьбе с переуверенностью.

\section{Вычислительные эксперименты}\label{sec:experiments}

\subsection{Дизайн экспериментов}

В экспериментах были использованы следующие наборы данных:
\begin{itemize}
    \item \textbf{CIFAR-10} \cite{cifar}: Датасет содержит $60\,000$ цветных изображений $32\times 32$, каждое относится к одному из 10 классов. Разделение на \emph{обучающую} / \emph{валидационную} / \emph{тестовую} выборки: $50\,000\;/\;5\,000\;/\;5\,000$ изображений.
    \item \textbf{CIFAR-100} \cite{cifar}: $60\,000$ цветных изображений $32\times 32$, 100 классов. \emph{Обучение} / \emph{валидация} / \emph{тест}: $50\,000\;/\;5\,000\;/\;5\,000$.
    \item \textbf{ImageNet 2012} \cite{imagenet}: Крупный датасет с изображениями, разбитыми на 1000 классов. \emph{Обучение} / \emph{валидация} / \emph{тест}: $1.2\;\text{млн}\;/\;25\,000\;/\;25\,000$.
    \item \textbf{Tiny ImageNet} \cite{imagenet}: $110\,000$ изображений $64\times 64$, разделенных на 200 классов. Является подмножеством предыдущего датасета. \emph{Обучение} / \emph{валидация} / \emph{тест}: $100\,000\;/\;5\,000\;/\;5\,000$.
\end{itemize}

Для вычислений использовались предобученные нейронные сети с различными архитектурами из открытых репозиториев. В экспериментах модели и датасеты разбиты на две основные группы:

\begin{enumerate}
    \item К первой группе отнесены нейронные сети, обученные на CIFAR-10, CIFAR-100, ImageNet. Веса для моделей были взяты соответственно из репозиториев \cite{pretrained_cifar10, pretrained_cifar100, pretrained_imagenet}. Модели данной группы используются для сравнения методов калибровки, основанных на постобработке.
    \item Ко второй группе отнесены предобученные нейросети из репозитория \cite{focal_github}. Здесь использованы датасеты CIFAR-10, CIFAR-100 и Tiny ImageNet. Данные нейросети были обучены для статьи \cite{focal_calib}~--- для части из них использовалась фокальная ошибка и сглаживание меток.
\end{enumerate}

При обучении модели настраивались на данные из \emph{обучающей} выборки (или ее части), калибровались на \emph{отложенной (валидационной)} выборке. Все построенные диаграммы надежности и метрики соответствуют \emph{тестовой} выборке.

Все эксперименты, реализация методов калибровки и оценок были выполнены на языке Python. Температурное, векторное и матричное шкалирование настраивались на GPU и были реализованы с использованием библиотеки PyTorch, остальные методы и метрики реализованы с использованием библиотек SciPy и sklearn. При настройке гистограммного биннинга использовалось 20 бинов; ECE, cwECE и MCE считались с разбиением на 15 бинов.

\subsection{Результаты}
Полные таблицы с измерениями приведены в 
\hyperref[sec:appendix]{приложении} к работе, диаграммы надежности для всех рассмотренных моделей можно найти в репозитории \cite{my_repo}.
\addrel{1}{21}{}

Рассмотрим диаграммы надежности для ShuffleNetV2 (CIFAR-100, \autoref{fig:reldiag_1_21}): можно видеть <<типичное>> состояние откалиброванности нейросети --- переуверенность. Калибровка помогает исправить ситуацию: в данном случае лучше с точки зрения всех метрик лучше всего сработало температурное шкалирование. Гистограммный бинниг слишком агрессивно изменяет вероятности при большом числе классов (на отложенной выборке в бинах оказывается мало объектов).

Для малого числа классов, напротив, гистограммный биннинг работает лучше всего с точки зрения уверенности в предсказании (\autoref{tab:metrics:ECE_1}, \autoref{tab:metrics:ECE_2} --- почти для всех моделей на CIFAR-10). Но отметим, что здесь нейронные сети уже с очень высоким качеством решают задачу классификации. Почти все вероятности предсказанного класса близки к 1, как, например, на \autoref{fig:reldiag_2_1}. И с точки зрения MCE (\autoref{tab:metrics:MCE_1}, \autoref{tab:metrics:MCE_2}) --- метрики, в которой не учитываются <<веса>> бинов --- гистограммный биннинг дает низкое качество откалиброванности.
\addrel{2}{1}{}

Для матричного шкалирования мы не приводим диаграммы надежности: метод слишком сильно переобучается при большом числе классов. В итоге матричное шкалирование существенно ухудшает качество классификации (\autoref{tab:metrics:ACC_1}, \autoref{tab:metrics:ACC_1}) для всех датасетов, кроме, опять же, малоклассового CIFAR-10.

Одним из наиболее популярных методов калибровки нейросетей является температурное шкалирование. Метод действительно не оказывает влияния на классификацию, в то время как другие варианты калибровки почти всегда уменьшают точность (\autoref{tab:metrics:ACC_1}, \autoref{tab:metrics:ACC_2}). 

С точки зрения NLL ожидаемо лучшими оказались температурное и векторное шкалирование (ведь в процессе калибровки именно данная ошибки и оптимизировалась) --- \autoref{tab:metrics:NLL_1}, \autoref{tab:metrics:NLL_2}. Для Brier Score лучшим методом калибровки во многих случаях становилась изотоническая регрессия --- \autoref{tab:metrics:BS_1}, \autoref{tab:metrics:BS_2}. 

\begin{table}[h!]
    \begin{minipage}[h!]{0.47\textwidth}
        \input{tabs/fl_ECE.tex}
    \end{minipage}\hfill
    \begin{minipage}[h!]{0.47\textwidth}
        \input{tabs/fl_cwECE.tex}
    \end{minipage}
\end{table}
\addrel{1}{29}{}
Фокальная ошибка и сглаживание меток дают более откалибровнные модели, чем при настройке на стандартную кросс-энтропию — как с точки уверенности в предсказанном класса (\autoref{tab:fl:ECE}), так и с точки зрения поклассовых оценок (\autoref{tab:fl:cwECE}). При этом далее модели можно калибровать с помощью постобработки. В оригинальной работе \cite{focal_calib} для калибровки моделей, обученных на фокальную ошибку, использовалось только температурное шкалирование. Хотя относительно ECE (\autoref{tab:metrics:ECE_2}) такой подход действительно показывает высокие результаты, для поклассовой cwECE (\autoref{tab:metrics:cwECE_2}) лучше работает векторное шкалирование. Для моделей первой группы (\autoref{tab:metrics:cwECE_1}) векторное шкалирование тоже в основном минимизирует cwECE. Такие результаты вполне ожидаемы, поскольку векторное шкалирование находит отдельные коэффициенты деформации для каждого класса.

Рассмотрим также диаграммы калибровки для EfficientNet (\autoref{fig:reldiag_1_29}). Среди всех использованных моделей, у данной нейросети четче всего видна недоуверенность --- большая часть оценок сосредоточена не на $[0.9, 1]$, а на $[0.8, 0.9)$. Причина такого поведения может быть как раз в особенности обучения: модель обучалась со сглаживанием меток ($\alpha=0.1$) \cite{pretrained_imagenet}. Все методы калибровки привели к заметному повышению уверенности в ответах.


\section{Заключение}
% Таким образом, в данной работе было проведено сравнение основных методов калибровки уверенности.
Таким образом, в данной работе мы сравнили основные методы калибровки уверенности, проведя эксперименты с различными архитектурами нейронных сетей.

Применимость того или иного метода существенно зависит от количества данных и выбранного критерия качества. Алгоритмы, в которых строятся отдельные функции деформации для каждого класса, хорошо работают только при достаточном объеме данных в отложенной выборке (обычно это можно обеспечить, когда число классов невелико). Стратегии, в основе которых лежит линейное преобразование логитов (например, температурное шкалирование), показывают высокое качество в задачах с большим числом классов, но подвержены переобучению при чрезмерной параметризации (матричное шкалирование).

Калибровка уверенности до сих пор остается открытой проблемой в машинном обучении, и даже выбор корректного показателя качества откалиброванности может оказаться затруднительным.

\newpage
% \section{Список литературы}
\printbibliography[
    heading=bibintoc,
    title={Список литературы}
]

\newpage
\begin{appendices}\label{sec:appendix}
\section{Качество классификации моделей}
\input{tabs/metrics_ACC_1.tex}
\input{tabs/metrics_ACC_2.tex}
\clearpage

\section{Биннинговые метрики}
\input{tabs/metrics_ECE_1.tex}
\input{tabs/metrics_ECE_2.tex}
\input{tabs/metrics_cwECE_1.tex}
\input{tabs/metrics_cwECE_2.tex}
\input{tabs/metrics_MCE_1.tex}
\input{tabs/metrics_MCE_2.tex}
\clearpage

\section{Скоринговые ошибки}
\input{tabs/metrics_NLL_1.tex}
\input{tabs/metrics_NLL_2.tex}
\input{tabs/metrics_BS_1.tex}
\input{tabs/metrics_BS_2.tex}

\end{appendices}

\end{document}